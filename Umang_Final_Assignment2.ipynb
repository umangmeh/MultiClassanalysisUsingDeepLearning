{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Umang Final Assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZ0SB2fFsFo_",
        "colab_type": "text"
      },
      "source": [
        "Exploring The Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOP2cPb4sQh8",
        "colab_type": "code",
        "outputId": "c7a84f52-5278-4406-8ae5-bfd07e656ab5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2v58zkxukjt",
        "colab_type": "text"
      },
      "source": [
        "Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R168Clt_fj3E",
        "colab_type": "code",
        "outputId": "1014f1cc-2a36-4097-b39d-a61dbf808a93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNNfqT8pwYtH",
        "colab_type": "text"
      },
      "source": [
        "Reading Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFAPjTy-tksm",
        "colab_type": "code",
        "outputId": "bc8a0699-dbff-40f6-f97a-deb09cd4bcfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "dataset =  pd.read_csv('/content/drive/My Drive/Assignment 2/train.tsv', sep='\\t')\n",
        "dataset = dataset.dropna()\n",
        "dataset.head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>A series of escapades demonstrating the adage ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>A series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>A</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>series</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBnd7GiNvr7X",
        "colab_type": "code",
        "outputId": "a8c1f0ce-3b6f-4e71-e817-ac46ff73799e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "dataset.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(156060, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gK36cXc2vw4A",
        "colab_type": "code",
        "outputId": "4ec1ad88-dba1-4d66-8f8c-2f4142ecca8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "dataset.Sentiment.value_counts()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    79582\n",
              "3    32927\n",
              "1    27273\n",
              "4     9206\n",
              "0     7072\n",
              "Name: Sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVUp6R5OxGFK",
        "colab_type": "text"
      },
      "source": [
        "Adjustable Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzyu99V_UvFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "remove_fPunct = True\n",
        "fTokenizaton = True\n",
        "fStopwords = True\n",
        "fStemming = False\n",
        "fLemmatization = True\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKtODFJPVEPf",
        "colab_type": "text"
      },
      "source": [
        "Data Cleaning | Punctuations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXvOmk8F_fyb",
        "colab_type": "code",
        "outputId": "0cbf3321-dbd9-4176-a514-6013f8115018",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import string\n",
        "print(string.punctuation)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XN4KMFgCDAXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_punctuation(text):\n",
        "  txt_nonpunct = \"\".join([a for a in text if a not in string.punctuation])\n",
        "  return txt_nonpunct "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRn28Jk_DYGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if remove_fPunct:\n",
        "  dataset['Phrase'] = dataset['Phrase'].apply(lambda x: remove_punctuation(x)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J_1XQfsFf9G",
        "colab_type": "text"
      },
      "source": [
        "Data Cleaning | Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbimWUGpFiOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "\n",
        "def tokenize(text):\n",
        "  tokens = re.split('\\W+', text)\n",
        "  return tokens \n",
        "\n",
        "if fTokenizaton:\n",
        "  dataset['Phrase'] = dataset['Phrase'].apply(lambda x: tokenize(x.lower()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxMQGrRuHhse",
        "colab_type": "text"
      },
      "source": [
        "Data Cleaning | Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihAJokODHp_L",
        "colab_type": "code",
        "outputId": "8178e826-5a96-4319-ceca-f09e6ded144a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# import nltk\n",
        "# nltk.download('stopwords')\n",
        "\n",
        "# h = nltk.download('stopwords')\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "stopwords[0:10]\n",
        "# h"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI3ZmGYJIB9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_stopwords(txt_tokenized):\n",
        "  txt_clean = [word for word in txt_tokenized if word not in stopwords]\n",
        "  return txt_clean\n",
        "\n",
        "if fStopwords:\n",
        "  dataset['Phrase'] = dataset['Phrase'].apply(lambda x: remove_stopwords(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ibpBZGoKV8V",
        "colab_type": "text"
      },
      "source": [
        "Data Cleaning | Stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV5IpZ6jKYlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "# from nltk.stem import snowballstemmer\n",
        "ps = PorterStemmer()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uj82xnvRkuo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stemming(tokenized_text):\n",
        "  text = [ps.stem(word) for word in tokenized_text]\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzILzo4UNcYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if fStemming:\n",
        "  dataset['Phrase'] = dataset['Phrase'].apply(lambda x: stemming(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_YooGKsSA8P",
        "colab_type": "text"
      },
      "source": [
        "Data Cleaning | Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfcWAnNxSERs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wn = nltk.WordNetLemmatizer()\n",
        "ps = nltk.PorterStemmer()\n",
        "\n",
        "def lemmatization(token_txt):\n",
        "  text = [wn.lemmatize(word) for word in token_txt]\n",
        "  return text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7NG1Jq8SGzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if fLemmatization:\n",
        "  dataset['Phrase'] = dataset['Phrase'].apply(lambda x: lemmatization(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XbNHQyTSWuiv",
        "colab_type": "code",
        "outputId": "c30f78f2-6e72-42ec-a4d1-6c1cfa6a9236",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[series, escapade, demonstrating, adage, good,...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>[series, escapade, demonstrating, adage, good,...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>[series]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>[]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>[series]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PhraseId  ...  Sentiment\n",
              "0         1  ...          1\n",
              "1         2  ...          2\n",
              "2         3  ...          2\n",
              "3         4  ...          2\n",
              "4         5  ...          2\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd8NXFfo_nk8",
        "colab_type": "code",
        "outputId": "2fcfdd7d-aa2d-40c7-f087-0518452cdc5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "source": [
        "import random\n",
        "random.seed(9001)\n",
        "newData = dataset.to_numpy()\n",
        "print(newData)\n",
        "np.random.shuffle(newData)\n",
        "# print(\"New data\", newData)\n",
        "\n",
        "xyz = pd.DataFrame(newData,columns=['PhraseId','SentenceId','Phrase','Sentiment'])\n",
        "# xyz.head()\n",
        "\n",
        "dataset = xyz\n",
        "dataset.head()"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 1\n",
            "  list(['series', 'escapade', 'demonstrating', 'adage', 'good', 'goose', 'also', 'good', 'gander', 'occasionally', 'amuses', 'none', 'amount', 'much', 'story', ''])\n",
            "  1]\n",
            " [2 1\n",
            "  list(['series', 'escapade', 'demonstrating', 'adage', 'good', 'goose'])\n",
            "  2]\n",
            " [3 1 list(['series']) 2]\n",
            " ...\n",
            " [156058 8544 list(['avuncular', 'chortle']) 3]\n",
            " [156059 8544 list(['avuncular']) 2]\n",
            " [156060 8544 list(['chortle']) 2]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PhraseId</th>\n",
              "      <th>SentenceId</th>\n",
              "      <th>Phrase</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>97453</td>\n",
              "      <td>5096</td>\n",
              "      <td>[android]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>58468</td>\n",
              "      <td>2946</td>\n",
              "      <td>[favor, mushy, obviousness]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>58182</td>\n",
              "      <td>2932</td>\n",
              "      <td>[merely, kicking, undead, ]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>120984</td>\n",
              "      <td>6479</td>\n",
              "      <td>[played, ryan, gosling]</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>61856</td>\n",
              "      <td>3127</td>\n",
              "      <td>[movie, weighs, glass, flat, champagne, ]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  PhraseId SentenceId                                     Phrase Sentiment\n",
              "0    97453       5096                                  [android]         2\n",
              "1    58468       2946                [favor, mushy, obviousness]         2\n",
              "2    58182       2932                [merely, kicking, undead, ]         2\n",
              "3   120984       6479                    [played, ryan, gosling]         2\n",
              "4    61856       3127  [movie, weighs, glass, flat, champagne, ]         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LblhFFl7eyxd",
        "colab_type": "text"
      },
      "source": [
        "Splitting The Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XebxMLR5hBoO",
        "colab_type": "code",
        "outputId": "cec9b6f7-8c4b-4498-fb0e-e2cf466383b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        }
      },
      "source": [
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset['Phrase'], dataset['Sentiment'], test_size=0.3, random_state=2003)\n",
        "documents = []\n",
        "X_train = np.array(X_train.values.tolist())\n",
        "Y_train = np.array(Y_train.values.tolist())\n",
        "for i in range(len(X_train)):\n",
        "  documents.append([list(X_train[i]), Y_train[i]]) \n",
        "\n",
        "X_test = np.array(X_test.values.tolist())\n",
        "Y_test = np.array(Y_test.values.tolist())\n",
        "for i in range(len(X_test)):\n",
        "  documents.append([list(X_test[i]), Y_test[i]]) \n",
        "\n",
        "print(documents[0][0])\n",
        "# for i in documents:\n",
        "#   print(i)\n",
        "# for i range(len(documents)):\n",
        "#   label = documents[i][1]\n",
        "#   documents[i] = \n",
        "\n",
        "dataset = pd.DataFrame(documents, columns=['text', 'sentiment']) \n",
        "dataset['join'] = dataset.text.apply(' '.join)\n",
        "# print(documents)\n",
        "dataset.head()"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['never', 'truly', 'come', 'care', 'main', 'character', 'whether', 'wind', 'together']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>join</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[never, truly, come, care, main, character, wh...</td>\n",
              "      <td>1</td>\n",
              "      <td>never truly come care main character whether w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[nt, funny]</td>\n",
              "      <td>1</td>\n",
              "      <td>nt funny</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[seller, smart, woman]</td>\n",
              "      <td>2</td>\n",
              "      <td>seller smart woman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[could, make, decent, budget]</td>\n",
              "      <td>3</td>\n",
              "      <td>could make decent budget</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[star, nia, vardalos]</td>\n",
              "      <td>2</td>\n",
              "      <td>star nia vardalos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                                               join\n",
              "0  [never, truly, come, care, main, character, wh...  ...  never truly come care main character whether w...\n",
              "1                                        [nt, funny]  ...                                           nt funny\n",
              "2                             [seller, smart, woman]  ...                                 seller smart woman\n",
              "3                      [could, make, decent, budget]  ...                           could make decent budget\n",
              "4                              [star, nia, vardalos]  ...                                  star nia vardalos\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxPION4LRazd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset['join'],  dataset['sentiment'], test_size=0.3, random_state=2003)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgA0Y2-401nv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features = 2500)\n",
        "X = vectorizer.fit_transform(dataset[\"join\"]) \n",
        "Y = dataset['sentiment'] \n",
        " \n",
        "X_train = vectorizer.transform(X_train).toarray()\n",
        "Y_train = Y_train \n",
        "X_test = vectorizer.transform(X_test).toarray()\n",
        "Y_test = Y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dD4ZenB6Cx-B",
        "colab_type": "code",
        "outputId": "051904b6-77a9-434c-e52a-5295232b3ce1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "Y_test"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13510     2\n",
              "61932     2\n",
              "82549     3\n",
              "137718    3\n",
              "121990    3\n",
              "         ..\n",
              "94224     2\n",
              "135456    2\n",
              "154729    1\n",
              "23031     1\n",
              "57870     1\n",
              "Name: sentiment, Length: 46818, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFwYA1tWwnhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGCqfGuqSaJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PArHaS33h9Ge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def recall_method(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_method(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    precision = precision_method(y_true, y_pred)\n",
        "    recall = recall_method(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1owiJVMm7Com",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uj80Ku2Socv",
        "colab_type": "code",
        "outputId": "4baf5acb-4dd3-4007-bcc8-9a45cc44c3ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(109242, 2500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYgWOcu3S_U2",
        "colab_type": "code",
        "outputId": "c7c9a6a8-8a77-4bc6-949b-d211f53ec23c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
        "Y_test = keras.utils.to_categorical(Y_test, num_classes)\n",
        "Y_test"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hHjUmvCe_2l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "9a2b6c22-8160-459f-ed7c-54fd5778499a"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3,\n",
        "                 activation='relu',\n",
        "                 input_shape=(2500,1)))\n",
        "\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=1))\n",
        "model.add(Dropout(rate = 0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_4 (Conv1D)            (None, 2498, 64)          256       \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, 2496, 64)          12352     \n",
            "_________________________________________________________________\n",
            "conv1d_6 (Conv1D)            (None, 2494, 64)          12352     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 2494, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2494, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 159616)            0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                10215488  \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 10,240,773\n",
            "Trainable params: 10,240,773\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "re4qdVOifhJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adam(),\n",
        "              metrics=['accuracy',f1_score,precision_method,recall_method])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWnLccEfgKbH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RONgsKL5gkqQ",
        "colab_type": "code",
        "outputId": "30f2e6fc-141c-4be0-c6b0-80fb70bd334b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "model.fit(X_train, Y_train,\n",
        "          batch_size=32,\n",
        "          epochs=10)\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "\n",
        "\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "109242/109242 [==============================] - 117s 1ms/step - loss: 1.0467 - acc: 0.5877 - f1_score: 0.5187 - precision_method: 0.6576 - recall_method: 0.4349\n",
            "Epoch 2/10\n",
            "109242/109242 [==============================] - 117s 1ms/step - loss: 0.9469 - acc: 0.6289 - f1_score: 0.5924 - precision_method: 0.6879 - recall_method: 0.5228\n",
            "Epoch 3/10\n",
            "109242/109242 [==============================] - 117s 1ms/step - loss: 0.8968 - acc: 0.6510 - f1_score: 0.6220 - precision_method: 0.6963 - recall_method: 0.5642\n",
            "Epoch 4/10\n",
            "109242/109242 [==============================] - 117s 1ms/step - loss: 0.8575 - acc: 0.6648 - f1_score: 0.6442 - precision_method: 0.7055 - recall_method: 0.5944\n",
            "Epoch 5/10\n",
            "109242/109242 [==============================] - 117s 1ms/step - loss: 0.8244 - acc: 0.6789 - f1_score: 0.6603 - precision_method: 0.7134 - recall_method: 0.6161\n",
            "Epoch 6/10\n",
            "109242/109242 [==============================] - 116s 1ms/step - loss: 0.7987 - acc: 0.6862 - f1_score: 0.6716 - precision_method: 0.7187 - recall_method: 0.6316\n",
            "Epoch 7/10\n",
            "109242/109242 [==============================] - 118s 1ms/step - loss: 0.7773 - acc: 0.6953 - f1_score: 0.6828 - precision_method: 0.7260 - recall_method: 0.6457\n",
            "Epoch 8/10\n",
            "  6432/109242 [>.............................] - ETA: 1:50 - loss: 0.7059 - acc: 0.7220 - f1_score: 0.7131 - precision_method: 0.7466 - recall_method: 0.6835"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCNWibxs6Unu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model.save('/content/drive/My Drive/Assignment 2/1117269_1dconv_reg.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}